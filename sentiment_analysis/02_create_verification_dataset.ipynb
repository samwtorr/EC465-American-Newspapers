{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: Create Verification Dataset (Two-Axis)\n",
    "\n",
    "Build training/validation datasets for **two separate models**:\n",
    "- **Labor stance model**: pro-labor / anti-labor / neutral (trained on labor + both articles)\n",
    "- **Railroad outlook model**: optimistic / pessimistic / neutral (trained on railroad + both articles)\n",
    "\n",
    "\"Both\" articles are labeled on **both axes**.\n",
    "\n",
    "**Critical**: Validation sets are **100% hand-labeled** to avoid circularity with Gemini labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(os.path.join('..', '.env'))\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler(\"data/verification_log.log\")\n",
    "    ]\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "OUTPUT_DIR = Path(\"data/verified_labels\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CLASSIFIED_DIR = Path(\"data/classified_articles\")\n",
    "\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(filepath, data):\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labor: 74,001\n",
      "Railroad: 100,000\n",
      "Both: 17,873\n"
     ]
    }
   ],
   "source": [
    "# Load classified articles\n",
    "labor_articles = load_json(CLASSIFIED_DIR / 'labor_only.json')\n",
    "railroad_articles = load_json(CLASSIFIED_DIR / 'railroad_only.json')\n",
    "both_articles = load_json(CLASSIFIED_DIR / 'both.json')\n",
    "\n",
    "print(f\"Labor: {len(labor_articles):,}\")\n",
    "print(f\"Railroad: {len(railroad_articles):,}\")\n",
    "print(f\"Both: {len(both_articles):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword utils loaded.\n",
      "  Labor patterns: 26\n",
      "  Railroad patterns: 20\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import html as html_module\n",
    "\n",
    "# Keyword definitions (from Stage 1) for centering + highlighting\n",
    "LABOR_KEYWORDS = {\n",
    "    'labor union': 3, 'trade union': 3, 'labor strike': 3, 'labor riot': 3,\n",
    "    'collective bargaining': 3, 'labor movement': 3, 'strikebreaker': 3,\n",
    "    'scab labor': 3, 'working men': 3, 'workingmen': 3,\n",
    "    'knights of labor': 3, 'eight hour': 3,\n",
    "    'striker': 2, 'strikers': 2, 'picket': 2, 'lockout': 2,\n",
    "    'boycott': 2, 'walkout': 2, 'arbitration': 2, 'picketing': 2,\n",
    "    'strike': 1, 'strikes': 1, 'wage': 1, 'wages': 1,\n",
    "    'workers': 1, 'laborers': 1,\n",
    "}\n",
    "RAILROAD_KEYWORDS = {\n",
    "    'railroad company': 3, 'railroad strike': 3, 'railroad workers': 3,\n",
    "    'railway company': 3, 'union pacific': 3, 'central pacific': 3,\n",
    "    'northern pacific': 3, 'pennsylvania railroad': 3,\n",
    "    'baltimore and ohio': 3, 'railroad line': 3,\n",
    "    'locomotive': 2, 'locomotives': 2, 'brakeman': 2,\n",
    "    'freight car': 2, 'passenger car': 2, 'rail road': 2,\n",
    "    'railroad': 1, 'railway': 1, 'train': 1, 'trains': 1,\n",
    "}\n",
    "\n",
    "LABOR_PATTERNS = {kw: (re.compile(r'\\b' + re.escape(kw) + r'\\b', re.IGNORECASE), w)\n",
    "                  for kw, w in LABOR_KEYWORDS.items()}\n",
    "RAILROAD_PATTERNS = {kw: (re.compile(r'\\b' + re.escape(kw) + r'\\b', re.IGNORECASE), w)\n",
    "                     for kw, w in RAILROAD_KEYWORDS.items()}\n",
    "\n",
    "\n",
    "def find_keyword_matches(text, category):\n",
    "    \"\"\"Return all keyword matches as (start, end, keyword, weight, axis).\"\"\"\n",
    "    matches = []\n",
    "    if category in ('labor', 'both'):\n",
    "        for kw, (regex, weight) in LABOR_PATTERNS.items():\n",
    "            for m in regex.finditer(text):\n",
    "                matches.append((m.start(), m.end(), kw, weight, 'labor'))\n",
    "    if category in ('railroad', 'both'):\n",
    "        for kw, (regex, weight) in RAILROAD_PATTERNS.items():\n",
    "            for m in regex.finditer(text):\n",
    "                matches.append((m.start(), m.end(), kw, weight, 'railroad'))\n",
    "    matches.sort(key=lambda x: (-x[3], x[0]))\n",
    "    return matches\n",
    "\n",
    "\n",
    "def best_keyword_position(text, category):\n",
    "    \"\"\"Return char position of the highest-weighted keyword match.\"\"\"\n",
    "    matches = find_keyword_matches(text, category)\n",
    "    return matches[0][0] if matches else 0\n",
    "\n",
    "\n",
    "def keyword_centered_excerpt(text, category, window=2000):\n",
    "    \"\"\"Extract text centered on the best keyword match. Returns (excerpt, offset).\"\"\"\n",
    "    if len(text) <= window:\n",
    "        return text, 0\n",
    "    center = best_keyword_position(text, category)\n",
    "    half = window // 2\n",
    "    start = max(0, center - half)\n",
    "    end = start + window\n",
    "    if end > len(text):\n",
    "        end = len(text)\n",
    "        start = max(0, end - window)\n",
    "    return text[start:end], start\n",
    "\n",
    "\n",
    "def highlight_keywords_html(text, category):\n",
    "    \"\"\"Return HTML with keyword matches highlighted in color.\"\"\"\n",
    "    matches = find_keyword_matches(text, category)\n",
    "    # Deduplicate overlapping matches (keep highest weight)\n",
    "    used_ranges = []\n",
    "    filtered = []\n",
    "    for start, end, kw, weight, axis in matches:\n",
    "        if not any(start < ue and end > us for us, ue in used_ranges):\n",
    "            filtered.append((start, end, kw, weight, axis))\n",
    "            used_ranges.append((start, end))\n",
    "    filtered.sort(key=lambda x: x[0])\n",
    "\n",
    "    result = []\n",
    "    last_end = 0\n",
    "    for start, end, kw, weight, axis in filtered:\n",
    "        result.append(html_module.escape(text[last_end:start]))\n",
    "        color = '#ff9800' if axis == 'labor' else '#2196f3'\n",
    "        matched = html_module.escape(text[start:end])\n",
    "        result.append(\n",
    "            f'<span style=\"background:{color}; color:white; '\n",
    "            f'padding:1px 4px; border-radius:3px; font-weight:bold;\" '\n",
    "            f'title=\"{axis} (weight {weight})\">{matched}</span>'\n",
    "        )\n",
    "        last_end = end\n",
    "    result.append(html_module.escape(text[last_end:]))\n",
    "    return ''.join(result)\n",
    "\n",
    "\n",
    "print(\"Keyword utils loaded.\")\n",
    "print(f\"  Labor patterns: {len(LABOR_PATTERNS)}\")\n",
    "print(f\"  Railroad patterns: {len(RAILROAD_PATTERNS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling sample: 1000 articles\n",
      "  labor: 333\n",
      "  railroad: 333\n",
      "  both: 334\n"
     ]
    }
   ],
   "source": [
    "# Build stratified sample: ~334 from each category\n",
    "HAND_LABEL_TARGET = 1000\n",
    "per_category = HAND_LABEL_TARGET // 3\n",
    "\n",
    "sample = (\n",
    "    random.sample(labor_articles, min(per_category, len(labor_articles)))\n",
    "    + random.sample(railroad_articles, min(per_category, len(railroad_articles)))\n",
    "    + random.sample(both_articles, min(per_category + (HAND_LABEL_TARGET % 3), len(both_articles)))\n",
    ")\n",
    "random.shuffle(sample)\n",
    "\n",
    "print(f\"Labeling sample: {len(sample)} articles\")\n",
    "for cat in ['labor', 'railroad', 'both']:\n",
    "    print(f\"  {cat}: {sum(1 for a in sample if a['category'] == cat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming: 56 already labeled, 1000 remaining\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c74a28e27aa4824a33a78e08e4c3204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=56, description='Progress:', layout=Layout(width='100%'), max=1056)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01480b418994643b5e154005e8c6337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='', layout=Layout(border_bottom='1px solid #ccc', border_left='1px solid #ccc', border_right='1px s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e388e30fc649aeb7d72f86a165ec5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Category:', layout=Layout(width='400px'), options=('Labor', 'Railroad', 'Both', 'Nei…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb23fe0b6f0470397e963ab2bc1d1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<b>Labor Stance</b> (editorial position on workers/unions)'), RadioB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a9360dc64e4710a9b30f62907e95fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='primary', description='Save & Next', layout=Layout(width='150px'), style=B…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "HAND_LABELED_FILE = OUTPUT_DIR / 'hand_labeled.json'\n",
    "\n",
    "\n",
    "class ArticleLabelingTool:\n",
    "    def __init__(self, articles: list, output_file: Path):\n",
    "        self.articles = articles\n",
    "        self.output_file = output_file\n",
    "        self.labels = []\n",
    "        self.current_idx = 0\n",
    "\n",
    "        # Resume from existing labels\n",
    "        if output_file.exists():\n",
    "            self.labels = load_json(output_file)\n",
    "            labeled_ids = {l['article_id'] for l in self.labels}\n",
    "            self.articles = [a for a in self.articles if a['article_id'] not in labeled_ids]\n",
    "            print(f\"Resuming: {len(self.labels)} already labeled, {len(self.articles)} remaining\")\n",
    "\n",
    "    def create_ui(self):\n",
    "        self.text_widget = widgets.HTML(\n",
    "            layout=widgets.Layout(width='100%', max_height='400px', overflow_y='auto',\n",
    "                                  border='1px solid #ccc', padding='10px')\n",
    "        )\n",
    "\n",
    "        self.category_widget = widgets.RadioButtons(\n",
    "            options=['Labor', 'Railroad', 'Both', 'Neither (misclassified)'],\n",
    "            description='Category:',\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "\n",
    "        # Labor stance (shown for labor + both)\n",
    "        self.labor_sentiment_widget = widgets.RadioButtons(\n",
    "            options=['Pro-Labor', 'Anti-Labor', 'Neutral'],\n",
    "            description='Labor stance:',\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        self.labor_box = widgets.VBox([\n",
    "            widgets.HTML('<b>Labor Stance</b> (editorial position on workers/unions)'),\n",
    "            self.labor_sentiment_widget\n",
    "        ])\n",
    "\n",
    "        # Railroad outlook (shown for railroad + both)\n",
    "        self.railroad_sentiment_widget = widgets.RadioButtons(\n",
    "            options=['Optimistic', 'Pessimistic', 'Neutral'],\n",
    "            description='RR outlook:',\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        self.railroad_box = widgets.VBox([\n",
    "            widgets.HTML('<b>Railroad Outlook</b> (framing of railroad industry)'),\n",
    "            self.railroad_sentiment_widget\n",
    "        ])\n",
    "\n",
    "        self.sentiment_row = widgets.HBox([self.labor_box, self.railroad_box])\n",
    "\n",
    "        next_btn = widgets.Button(description='Save & Next', button_style='primary',\n",
    "                                  layout=widgets.Layout(width='150px'))\n",
    "        next_btn.on_click(self._save_and_next)\n",
    "\n",
    "        skip_btn = widgets.Button(description='Skip', button_style='warning',\n",
    "                                  layout=widgets.Layout(width='100px'))\n",
    "        skip_btn.on_click(self._skip)\n",
    "\n",
    "        self.progress = widgets.IntProgress(\n",
    "            value=len(self.labels),\n",
    "            min=0,\n",
    "            max=len(self.labels) + len(self.articles),\n",
    "            description='Progress:',\n",
    "            layout=widgets.Layout(width='100%')\n",
    "        )\n",
    "\n",
    "        self.status_label = widgets.Label(value='')\n",
    "        button_row = widgets.HBox([next_btn, skip_btn, self.status_label])\n",
    "\n",
    "        # Watch category changes to show/hide sentiment widgets\n",
    "        self.category_widget.observe(self._on_category_change, names='value')\n",
    "\n",
    "        display(self.progress, self.text_widget, self.category_widget,\n",
    "                self.sentiment_row, button_row)\n",
    "\n",
    "        if self.articles:\n",
    "            self._load_article(0)\n",
    "        else:\n",
    "            self.text_widget.value = '<h2>All articles have been labeled!</h2>'\n",
    "\n",
    "    def _on_category_change(self, change):\n",
    "        \"\"\"Show/hide sentiment widgets based on category.\"\"\"\n",
    "        cat = change['new']\n",
    "        self.labor_box.layout.display = '' if cat in ('Labor', 'Both') else 'none'\n",
    "        self.railroad_box.layout.display = '' if cat in ('Railroad', 'Both') else 'none'\n",
    "\n",
    "    def _load_article(self, idx):\n",
    "        article = self.articles[idx]\n",
    "        category = article['category']\n",
    "\n",
    "        # Center on the best keyword match\n",
    "        excerpt, offset = keyword_centered_excerpt(article['text'], category, window=2000)\n",
    "\n",
    "        # Highlight keywords in the excerpt\n",
    "        highlighted = highlight_keywords_html(excerpt, category)\n",
    "        highlighted = highlighted.replace('\\n', '<br>')\n",
    "\n",
    "        offset_note = f\" | <b>Showing chars {offset}\\u2013{offset+len(excerpt)}</b> of {len(article['text'])}\" if offset > 0 else \"\"\n",
    "\n",
    "        self.text_widget.value = (\n",
    "            f\"<h3>Article {len(self.labels) + 1} / {self.progress.max}</h3>\"\n",
    "            f\"<p><b>Year:</b> {article['year']} | \"\n",
    "            f\"<b>ISSN:</b> {article['issn']} | \"\n",
    "            f\"<b>Category:</b> {article['category']}</p>\"\n",
    "            f\"<p><b>Labor score:</b> {article.get('labor_score', '?')} | \"\n",
    "            f\"<b>Railroad score:</b> {article.get('railroad_score', '?')}\"\n",
    "            f\"{offset_note}</p>\"\n",
    "            f\"<p style='font-size:11px;'>\"\n",
    "            f\"<span style='background:#ff9800; color:white; padding:1px 4px; \"\n",
    "            f\"border-radius:3px;'>Labor keywords</span> \"\n",
    "            f\"<span style='background:#2196f3; color:white; padding:1px 4px; \"\n",
    "            f\"border-radius:3px;'>Railroad keywords</span></p>\"\n",
    "            f\"<hr><p style='font-family: serif; font-size: 14px; \"\n",
    "            f\"line-height: 1.6;'>{highlighted}</p>\"\n",
    "        )\n",
    "\n",
    "        cat_map = {'labor': 'Labor', 'railroad': 'Railroad', 'both': 'Both'}\n",
    "        self.category_widget.value = cat_map.get(article['category'], 'Labor')\n",
    "        # Trigger visibility update\n",
    "        self._on_category_change({'new': self.category_widget.value})\n",
    "\n",
    "    def _save_and_next(self, _btn):\n",
    "        if self.current_idx >= len(self.articles):\n",
    "            return\n",
    "\n",
    "        article = self.articles[self.current_idx]\n",
    "        cat_map = {\n",
    "            'Labor': 'labor', 'Railroad': 'railroad',\n",
    "            'Both': 'both', 'Neither (misclassified)': 'neither',\n",
    "        }\n",
    "        labor_map = {'Pro-Labor': 'pro_labor', 'Anti-Labor': 'anti_labor', 'Neutral': 'neutral'}\n",
    "        rr_map = {'Optimistic': 'optimistic', 'Pessimistic': 'pessimistic', 'Neutral': 'neutral'}\n",
    "\n",
    "        verified_cat = cat_map[self.category_widget.value]\n",
    "\n",
    "        # Only record sentiments for the relevant axes\n",
    "        labor_sent = None\n",
    "        railroad_sent = None\n",
    "        if verified_cat in ('labor', 'both'):\n",
    "            labor_sent = labor_map[self.labor_sentiment_widget.value]\n",
    "        if verified_cat in ('railroad', 'both'):\n",
    "            railroad_sent = rr_map[self.railroad_sentiment_widget.value]\n",
    "\n",
    "        label = {\n",
    "            'article_id': article['article_id'],\n",
    "            'lccn': article['lccn'],\n",
    "            'issn': article['issn'],\n",
    "            'year': article['year'],\n",
    "            'text': article['text'],\n",
    "            'predicted_category': article['category'],\n",
    "            'verified_category': verified_cat,\n",
    "            'labor_sentiment': labor_sent,\n",
    "            'railroad_sentiment': railroad_sent,\n",
    "            'labeler': 'human',\n",
    "        }\n",
    "        self.labels.append(label)\n",
    "\n",
    "        save_json(self.output_file, self.labels)\n",
    "\n",
    "        self.current_idx += 1\n",
    "        self.progress.value = len(self.labels)\n",
    "        self.status_label.value = f'Saved. Total labeled: {len(self.labels)}'\n",
    "\n",
    "        if self.current_idx < len(self.articles):\n",
    "            self._load_article(self.current_idx)\n",
    "        else:\n",
    "            self.text_widget.value = f'<h2>Labeling complete! {len(self.labels)} articles labeled.</h2>'\n",
    "\n",
    "    def _skip(self, _btn):\n",
    "        self.current_idx += 1\n",
    "        if self.current_idx < len(self.articles):\n",
    "            self._load_article(self.current_idx)\n",
    "        else:\n",
    "            self.text_widget.value = '<h2>No more articles to label.</h2>'\n",
    "\n",
    "\n",
    "tool = ArticleLabelingTool(sample, HAND_LABELED_FILE)\n",
    "tool.create_ui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hand-labeled: 100\n",
      "\n",
      "Category distribution:\n",
      "  labor: 34\n",
      "  railroad: 23\n",
      "  both: 20\n",
      "  neither: 23\n",
      "Classification accuracy: 77.0%\n",
      "\n",
      "Labor stance distribution (54 articles):\n",
      "  pro_labor: 24 (44.4%)\n",
      "  anti_labor: 14 (25.9%)\n",
      "  neutral: 16 (29.6%)\n",
      "\n",
      "Railroad outlook distribution (43 articles):\n",
      "  optimistic: 15 (34.9%)\n",
      "  pessimistic: 8 (18.6%)\n",
      "  neutral: 20 (46.5%)\n"
     ]
    }
   ],
   "source": [
    "# Check labeling progress\n",
    "if HAND_LABELED_FILE.exists():\n",
    "    hand_labels = load_json(HAND_LABELED_FILE)\n",
    "    print(f\"Total hand-labeled: {len(hand_labels)}\")\n",
    "\n",
    "    # Category verification\n",
    "    categories = [l['verified_category'] for l in hand_labels]\n",
    "    print(f\"\\nCategory distribution:\")\n",
    "    for c in ['labor', 'railroad', 'both', 'neither']:\n",
    "        print(f\"  {c}: {categories.count(c)}\")\n",
    "    misclassified = categories.count('neither')\n",
    "    print(f\"Classification accuracy: {(len(categories) - misclassified) / len(categories) * 100:.1f}%\")\n",
    "\n",
    "    # Labor stance distribution (labor + both articles)\n",
    "    labor_labels = [l['labor_sentiment'] for l in hand_labels if l.get('labor_sentiment')]\n",
    "    if labor_labels:\n",
    "        print(f\"\\nLabor stance distribution ({len(labor_labels)} articles):\")\n",
    "        for s in ['pro_labor', 'anti_labor', 'neutral']:\n",
    "            count = labor_labels.count(s)\n",
    "            print(f\"  {s}: {count} ({count/len(labor_labels)*100:.1f}%)\")\n",
    "\n",
    "    # Railroad outlook distribution (railroad + both articles)\n",
    "    rr_labels = [l['railroad_sentiment'] for l in hand_labels if l.get('railroad_sentiment')]\n",
    "    if rr_labels:\n",
    "        print(f\"\\nRailroad outlook distribution ({len(rr_labels)} articles):\")\n",
    "        for s in ['optimistic', 'pessimistic', 'neutral']:\n",
    "            count = rr_labels.count(s)\n",
    "            print(f\"  {s}: {count} ({count/len(rr_labels)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"No hand labels found yet. Use the widget above to start labeling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2B. Gemini Verification (Training Data Only)\n",
    "\n",
    "Two separate Gemini prompts — one per axis. \"Both\" articles go through both prompts.\n",
    "\n",
    "Gemini labels are used **ONLY for training**, never validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini model: gemini-flash-latest\n",
      "API delay: 1s\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "GEMINI_MODEL = os.getenv(\"GEMINI_MODEL\", \"gemini-flash-latest\")\n",
    "GEMINI_API_DELAY = int(os.getenv(\"GEMINI_API_DELAY\", \"1\"))\n",
    "\n",
    "GENERATION_CONFIG = types.GenerateContentConfig(\n",
    "    temperature=0.1,\n",
    "    top_p=0.95,\n",
    "    top_k=40,\n",
    "    max_output_tokens=8192,\n",
    ")\n",
    "\n",
    "\n",
    "def query_gemini_api(prompt: str, retry_count: int = 3) -> str:\n",
    "    for attempt in range(retry_count):\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=GEMINI_MODEL,\n",
    "                contents=prompt,\n",
    "                config=GENERATION_CONFIG,\n",
    "            )\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            if \"quota\" in str(e).lower() or \"rate\" in str(e).lower():\n",
    "                wait_time = (attempt + 1) * 15\n",
    "                log.warning(f\"Rate limit hit, waiting {wait_time}s (attempt {attempt + 1}/{retry_count})\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                log.error(f\"Gemini API error: {e}\")\n",
    "                raise\n",
    "    raise Exception(f\"Failed after {retry_count} retries\")\n",
    "\n",
    "\n",
    "def parse_gemini_json(response: str) -> list:\n",
    "    response = response.strip()\n",
    "    if response.startswith(\"```json\"):\n",
    "        response = response[7:]\n",
    "    if response.startswith(\"```\"):\n",
    "        response = response[3:]\n",
    "    if response.endswith(\"```\"):\n",
    "        response = response[:-3]\n",
    "    return json.loads(response.strip())\n",
    "\n",
    "\n",
    "print(f\"Gemini model: {GEMINI_MODEL}\")\n",
    "print(f\"API delay: {GEMINI_API_DELAY}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labor Gemini sample: 100\n",
      "Railroad Gemini sample: 100\n"
     ]
    }
   ],
   "source": [
    "# Build Gemini samples — exclude hand-labeled articles\n",
    "hand_labeled_ids = set()\n",
    "if HAND_LABELED_FILE.exists():\n",
    "    hand_labeled_ids = {l['article_id'] for l in load_json(HAND_LABELED_FILE)}\n",
    "\n",
    "GEMINI_TARGET_PER_AXIS = 100\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# Labor axis: sample from labor + both (excluding hand-labeled)\n",
    "labor_pool = [a for a in labor_articles + both_articles if a['article_id'] not in hand_labeled_ids]\n",
    "labor_gemini_sample = random.sample(labor_pool, min(GEMINI_TARGET_PER_AXIS, len(labor_pool)))\n",
    "\n",
    "# Railroad axis: sample from railroad + both (excluding hand-labeled)\n",
    "railroad_pool = [a for a in railroad_articles + both_articles if a['article_id'] not in hand_labeled_ids]\n",
    "railroad_gemini_sample = random.sample(railroad_pool, min(GEMINI_TARGET_PER_AXIS, len(railroad_pool)))\n",
    "\n",
    "print(f\"Labor Gemini sample: {len(labor_gemini_sample)}\")\n",
    "print(f\"Railroad Gemini sample: {len(railroad_gemini_sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_gemini_verification() defined.\n"
     ]
    }
   ],
   "source": [
    "def run_gemini_verification(sample, prompt_builder, sentiment_key, output_file):\n",
    "    \"\"\"Run Gemini verification for one axis. Saves incrementally.\"\"\"\n",
    "    results = []\n",
    "    if output_file.exists():\n",
    "        results = load_json(output_file)\n",
    "        processed_ids = {r['article_id'] for r in results}\n",
    "        sample = [a for a in sample if a['article_id'] not in processed_ids]\n",
    "        print(f\"Resuming: {len(results)} done, {len(sample)} remaining\")\n",
    "\n",
    "    batches = [sample[i:i+BATCH_SIZE] for i in range(0, len(sample), BATCH_SIZE)]\n",
    "\n",
    "    for batch_idx, batch in enumerate(tqdm(batches, desc=f\"Gemini {sentiment_key}\")):\n",
    "        prompt = prompt_builder(batch)\n",
    "        try:\n",
    "            response = query_gemini_api(prompt)\n",
    "            batch_results = parse_gemini_json(response)\n",
    "\n",
    "            for j, result in enumerate(batch_results):\n",
    "                if j >= len(batch):\n",
    "                    break\n",
    "                article = batch[j]\n",
    "                entry = {\n",
    "                    'article_id': article['article_id'],\n",
    "                    'lccn': article['lccn'],\n",
    "                    'issn': article['issn'],\n",
    "                    'year': article['year'],\n",
    "                    'text': article['text'],\n",
    "                    'category': article['category'],\n",
    "                    sentiment_key: result.get(sentiment_key, 'neutral').lower(),\n",
    "                    'confidence': result.get('confidence', 'medium').lower(),\n",
    "                    'labeler': 'gemini',\n",
    "                }\n",
    "                results.append(entry)\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                save_json(output_file, results)\n",
    "                log.info(f\"Checkpoint: {len(results)} articles\")\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            log.error(f\"Batch {batch_idx}: JSON parse error: {e}\")\n",
    "        except Exception as e:\n",
    "            log.error(f\"Batch {batch_idx}: Error: {e}\")\n",
    "\n",
    "        time.sleep(GEMINI_API_DELAY)\n",
    "\n",
    "    save_json(output_file, results)\n",
    "    print(f\"Done: {len(results)} articles verified\")\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"run_gemini_verification() defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_labor_prompt(articles_batch: list) -> str:\n",
    "    articles_text = \"\"\n",
    "    for i, article in enumerate(articles_batch):\n",
    "        # Center excerpt on labor keywords\n",
    "        excerpt, _ = keyword_centered_excerpt(article['text'], 'labor', window=1000)\n",
    "        articles_text += (\n",
    "            f\"\\n--- ARTICLE {i + 1} ---\\n\"\n",
    "            f\"Year: {article['year']}\\n\"\n",
    "            f\"Text: {excerpt}\\n\"\n",
    "        )\n",
    "\n",
    "    return f\"\"\"You are analyzing historical American newspaper articles from 1869-1890 for editorial stance toward labor movements during the Gilded Age.\n",
    "\n",
    "For each article, determine the labor stance:\n",
    "- PRO_LABOR: Sympathizes with workers, justifies strikes, criticizes employers/owners\n",
    "- ANTI_LABOR: Condemns strikes as riots, supports employers, portrays unions as dangerous\n",
    "- NEUTRAL: Factual reporting without clear editorial bias\n",
    "\n",
    "Also rate your confidence: high, medium, or low.\n",
    "\n",
    "Return ONLY a valid JSON array (no markdown, no commentary):\n",
    "[\n",
    "  {{\"article_num\": 1, \"labor_sentiment\": \"pro_labor\", \"confidence\": \"high\"}},\n",
    "  ...\n",
    "]\n",
    "\n",
    "{articles_text}\"\"\"\n",
    "\n",
    "\n",
    "def build_railroad_prompt(articles_batch: list) -> str:\n",
    "    articles_text = \"\"\n",
    "    for i, article in enumerate(articles_batch):\n",
    "        # Center excerpt on railroad keywords\n",
    "        excerpt, _ = keyword_centered_excerpt(article['text'], 'railroad', window=1000)\n",
    "        articles_text += (\n",
    "            f\"\\n--- ARTICLE {i + 1} ---\\n\"\n",
    "            f\"Year: {article['year']}\\n\"\n",
    "            f\"Text: {excerpt}\\n\"\n",
    "        )\n",
    "\n",
    "    return f\"\"\"You are analyzing historical American newspaper articles from 1869-1890 for editorial framing of the railroad industry during the Gilded Age.\n",
    "\n",
    "For each article, determine the railroad outlook:\n",
    "- OPTIMISTIC: Celebrates expansion/progress, praises railroad companies, emphasizes economic benefits\n",
    "- PESSIMISTIC: Emphasizes accidents, corruption, monopoly power, financial failures, public harm\n",
    "- NEUTRAL: Factual reporting without clear editorial framing\n",
    "\n",
    "Also rate your confidence: high, medium, or low.\n",
    "\n",
    "Return ONLY a valid JSON array (no markdown, no commentary):\n",
    "[\n",
    "  {{\"article_num\": 1, \"railroad_sentiment\": \"pessimistic\", \"confidence\": \"high\"}},\n",
    "  ...\n",
    "]\n",
    "\n",
    "{articles_text}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Labor Stance Verification ===\n",
      "Resuming: 200 done, 100 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini labor_sentiment:   0%|          | 0/10 [00:00<?, ?it/s]2026-02-15 22:59:23,730 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:00:07,281 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini labor_sentiment:  10%|█         | 1/10 [00:44<06:41, 44.60s/it]2026-02-15 23:00:08,355 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:00:52,544 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini labor_sentiment:  20%|██        | 2/10 [01:29<05:59, 44.99s/it]2026-02-15 23:00:53,634 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:01:43,948 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini labor_sentiment:  30%|███       | 3/10 [02:21<05:35, 47.92s/it]2026-02-15 23:01:45,061 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:02:28,293 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini labor_sentiment:  40%|████      | 4/10 [03:05<04:39, 46.51s/it]2026-02-15 23:02:29,379 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:03:13,656 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini labor_sentiment:  50%|█████     | 5/10 [03:50<03:50, 46.10s/it]2026-02-15 23:03:14,744 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:03:28,507 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini labor_sentiment:  60%|██████    | 6/10 [04:05<02:21, 35.47s/it]2026-02-15 23:03:29,618 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:03:46,937 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini labor_sentiment:  70%|███████   | 7/10 [04:24<01:29, 29.90s/it]2026-02-15 23:03:48,008 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:04:31,789 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini labor_sentiment:  80%|████████  | 8/10 [05:09<01:09, 34.66s/it]2026-02-15 23:04:32,889 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:04:51,632 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini labor_sentiment:  90%|█████████ | 9/10 [05:28<00:30, 30.03s/it]2026-02-15 23:04:52,721 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:05:41,633 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "2026-02-15 23:05:41,680 [INFO] Checkpoint: 300 articles\n",
      "Gemini labor_sentiment: 100%|██████████| 10/10 [06:18<00:00, 37.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 300 articles verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run labor stance verification\n",
    "GEMINI_LABOR_FILE = OUTPUT_DIR / 'gemini_labor_verified.json'\n",
    "print(\"=== Labor Stance Verification ===\")\n",
    "gemini_labor = run_gemini_verification(\n",
    "    labor_gemini_sample, build_labor_prompt, 'labor_sentiment', GEMINI_LABOR_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Railroad Outlook Verification ===\n",
      "Resuming: 200 done, 99 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini railroad_sentiment:   0%|          | 0/10 [00:00<?, ?it/s]2026-02-15 23:05:42,841 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:05:52,956 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini railroad_sentiment:  10%|█         | 1/10 [00:11<01:40, 11.18s/it]2026-02-15 23:05:53,998 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:06:04,018 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini railroad_sentiment:  20%|██        | 2/10 [00:22<01:28, 11.10s/it]2026-02-15 23:06:05,077 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:06:12,806 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini railroad_sentiment:  30%|███       | 3/10 [00:31<01:10, 10.05s/it]2026-02-15 23:06:13,878 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:06:24,849 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini railroad_sentiment:  40%|████      | 4/10 [00:43<01:05, 10.83s/it]2026-02-15 23:06:25,907 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:06:41,594 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini railroad_sentiment:  50%|█████     | 5/10 [00:59<01:04, 12.97s/it]2026-02-15 23:06:42,642 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:06:51,308 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini railroad_sentiment:  60%|██████    | 6/10 [01:09<00:47, 11.86s/it]2026-02-15 23:06:52,399 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:07:35,755 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini railroad_sentiment:  70%|███████   | 7/10 [01:53<01:07, 22.52s/it]2026-02-15 23:07:36,823 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:07:48,051 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini railroad_sentiment:  80%|████████  | 8/10 [02:06<00:38, 19.28s/it]2026-02-15 23:07:49,181 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:08:06,258 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "Gemini railroad_sentiment:  90%|█████████ | 9/10 [02:24<00:18, 18.93s/it]2026-02-15 23:08:07,368 [INFO] AFC is enabled with max remote calls: 10.\n",
      "2026-02-15 23:08:16,118 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent \"HTTP/1.1 200 OK\"\n",
      "2026-02-15 23:08:16,156 [INFO] Checkpoint: 299 articles\n",
      "Gemini railroad_sentiment: 100%|██████████| 10/10 [02:34<00:00, 15.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 299 articles verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run railroad outlook verification\n",
    "GEMINI_RAILROAD_FILE = OUTPUT_DIR / 'gemini_railroad_verified.json'\n",
    "print(\"=== Railroad Outlook Verification ===\")\n",
    "gemini_railroad = run_gemini_verification(\n",
    "    railroad_gemini_sample, build_railroad_prompt, 'railroad_sentiment', GEMINI_RAILROAD_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Labor Gemini Stats ===\n",
      "Total: 300\n",
      "  anti_labor: 73 (24.3%)\n",
      "  neutral: 144 (48.0%)\n",
      "  pro_labor: 83 (27.7%)\n",
      "  High-confidence: 226 (75.3%)\n",
      "\n",
      "=== Railroad Gemini Stats ===\n",
      "Total: 299\n",
      "  neutral: 127 (42.5%)\n",
      "  optimistic: 85 (28.4%)\n",
      "  pessimistic: 87 (29.1%)\n",
      "  High-confidence: 253 (84.6%)\n"
     ]
    }
   ],
   "source": [
    "# Gemini label statistics\n",
    "for name, filepath, key in [\n",
    "    ('Labor', GEMINI_LABOR_FILE, 'labor_sentiment'),\n",
    "    ('Railroad', GEMINI_RAILROAD_FILE, 'railroad_sentiment'),\n",
    "]:\n",
    "    if filepath.exists():\n",
    "        gv = load_json(filepath)\n",
    "        print(f\"\\n=== {name} Gemini Stats ===\")\n",
    "        print(f\"Total: {len(gv)}\")\n",
    "        vals = [r.get(key, 'unknown') for r in gv]\n",
    "        for v in set(vals):\n",
    "            count = vals.count(v)\n",
    "            print(f\"  {v}: {count} ({count/len(vals)*100:.1f}%)\")\n",
    "        high = sum(1 for r in gv if r.get('confidence') == 'high')\n",
    "        print(f\"  High-confidence: {high} ({high/len(gv)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2C. Split into Two Model-Specific Datasets\n",
    "\n",
    "Each model gets its own train/val split. Validation is **100% hand-labeled**.\n",
    "\n",
    "- Labor model: trained on (labor + both) articles with `labor_sentiment` labels\n",
    "- Railroad model: trained on (railroad + both) articles with `railroad_sentiment` labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand = load_json(HAND_LABELED_FILE)\n",
    "\n",
    "# Filter out misclassified\n",
    "hand_valid = [l for l in hand if l['verified_category'] != 'neither']\n",
    "print(f\"Hand-labeled (excluding 'neither'): {len(hand_valid)}\")\n",
    "\n",
    "# Split hand-labeled by which axes they have labels for\n",
    "hand_with_labor = [l for l in hand_valid if l.get('labor_sentiment')]\n",
    "hand_with_railroad = [l for l in hand_valid if l.get('railroad_sentiment')]\n",
    "\n",
    "print(f\"  With labor stance: {len(hand_with_labor)} (labor + both articles)\")\n",
    "print(f\"  With railroad outlook: {len(hand_with_railroad)} (railroad + both articles)\")\n",
    "\n",
    "# --- Labor model split (60% train, 40% val) ---\n",
    "random.shuffle(hand_with_labor)\n",
    "split_labor = int(len(hand_with_labor) * 0.6)\n",
    "hand_labor_train = hand_with_labor[:split_labor]\n",
    "hand_labor_val = hand_with_labor[split_labor:]\n",
    "\n",
    "# Add Gemini high-confidence labor labels (training only)\n",
    "gemini_labor = load_json(GEMINI_LABOR_FILE)\n",
    "gemini_labor_high = [g for g in gemini_labor\n",
    "                     if g.get('confidence') == 'high'\n",
    "                     and g.get('labor_sentiment') in ('pro_labor', 'anti_labor', 'neutral')]\n",
    "\n",
    "labor_train = hand_labor_train + gemini_labor_high\n",
    "random.shuffle(labor_train)\n",
    "labor_val = hand_labor_val\n",
    "\n",
    "print(f\"\\n--- Labor Model Data ---\")\n",
    "print(f\"Training: {len(labor_train)} ({len(hand_labor_train)} hand + {len(gemini_labor_high)} Gemini)\")\n",
    "print(f\"Validation: {len(labor_val)} (100% hand-labeled)\")\n",
    "\n",
    "# --- Railroad model split (60% train, 40% val) ---\n",
    "random.shuffle(hand_with_railroad)\n",
    "split_rr = int(len(hand_with_railroad) * 0.6)\n",
    "hand_rr_train = hand_with_railroad[:split_rr]\n",
    "hand_rr_val = hand_with_railroad[split_rr:]\n",
    "\n",
    "gemini_railroad = load_json(GEMINI_RAILROAD_FILE)\n",
    "gemini_rr_high = [g for g in gemini_railroad\n",
    "                  if g.get('confidence') == 'high'\n",
    "                  and g.get('railroad_sentiment') in ('optimistic', 'pessimistic', 'neutral')]\n",
    "\n",
    "railroad_train = hand_rr_train + gemini_rr_high\n",
    "random.shuffle(railroad_train)\n",
    "railroad_val = hand_rr_val\n",
    "\n",
    "print(f\"\\n--- Railroad Model Data ---\")\n",
    "print(f\"Training: {len(railroad_train)} ({len(hand_rr_train)} hand + {len(gemini_rr_high)} Gemini)\")\n",
    "print(f\"Validation: {len(railroad_val)} (100% hand-labeled)\")\n",
    "\n",
    "# Distribution checks\n",
    "for name, data, key in [\n",
    "    ('Labor Train', labor_train, 'labor_sentiment'),\n",
    "    ('Labor Val', labor_val, 'labor_sentiment'),\n",
    "    ('Railroad Train', railroad_train, 'railroad_sentiment'),\n",
    "    ('Railroad Val', railroad_val, 'railroad_sentiment'),\n",
    "]:\n",
    "    vals = [d[key] for d in data if d.get(key)]\n",
    "    print(f\"\\n{name} ({len(vals)} samples):\")\n",
    "    for v in sorted(set(vals)):\n",
    "        count = vals.count(v)\n",
    "        print(f\"  {v}: {count} ({count/len(vals)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all four datasets\n",
    "save_json(OUTPUT_DIR / 'labor_train.json', labor_train)\n",
    "save_json(OUTPUT_DIR / 'labor_val.json', labor_val)\n",
    "save_json(OUTPUT_DIR / 'railroad_train.json', railroad_train)\n",
    "save_json(OUTPUT_DIR / 'railroad_val.json', railroad_val)\n",
    "\n",
    "print(\"Saved:\")\n",
    "for f in ['labor_train.json', 'labor_val.json', 'railroad_train.json', 'railroad_val.json']:\n",
    "    path = OUTPUT_DIR / f\n",
    "    print(f\"  {path} ({path.stat().st_size / 1e6:.1f} MB)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
