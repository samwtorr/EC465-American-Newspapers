{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Fine-Tune Two DistilBERT Sentiment Models\n",
    "\n",
    "**Run this notebook in Google Colab** with a T4 GPU (free tier).\n",
    "\n",
    "Trains two separate `distilbert-base-uncased` models sequentially:\n",
    "1. **Labor stance model**: pro_labor / anti_labor / neutral\n",
    "2. **Railroad outlook model**: optimistic / pessimistic / neutral\n",
    "\n",
    "Validation sets are **100% hand-labeled**. Uses **keyword-centered truncation** â€” tokens are\n",
    "centered on the highest-weighted keyword match rather than first/last tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Colab Setup ---\n",
    "# Uncomment the following lines when running in Colab:\n",
    "\n",
    "# !pip install -q transformers datasets accelerate scikit-learn\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# DATA_DIR = '/content/drive/MyDrive/sentiment_analysis/data/verified_labels'\n",
    "# MODEL_BASE_DIR = '/content/drive/MyDrive/sentiment_analysis/models'\n",
    "\n",
    "# For local testing, use:\n",
    "DATA_DIR = 'data/verified_labels'\n",
    "MODEL_BASE_DIR = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Keyword definitions for keyword-centered truncation ---\n",
    "LABOR_KEYWORDS = {\n",
    "    'labor union': 3, 'trade union': 3, 'labor strike': 3, 'labor riot': 3,\n",
    "    'collective bargaining': 3, 'labor movement': 3, 'strikebreaker': 3,\n",
    "    'scab labor': 3, 'working men': 3, 'workingmen': 3,\n",
    "    'knights of labor': 3, 'eight hour': 3,\n",
    "    'striker': 2, 'strikers': 2, 'picket': 2, 'lockout': 2,\n",
    "    'boycott': 2, 'walkout': 2, 'arbitration': 2, 'picketing': 2,\n",
    "    'strike': 1, 'strikes': 1, 'wage': 1, 'wages': 1,\n",
    "    'workers': 1, 'laborers': 1,\n",
    "}\n",
    "RAILROAD_KEYWORDS = {\n",
    "    'railroad company': 3, 'railroad strike': 3, 'railroad workers': 3,\n",
    "    'railway company': 3, 'union pacific': 3, 'central pacific': 3,\n",
    "    'northern pacific': 3, 'pennsylvania railroad': 3,\n",
    "    'baltimore and ohio': 3, 'railroad line': 3,\n",
    "    'locomotive': 2, 'locomotives': 2, 'brakeman': 2,\n",
    "    'freight car': 2, 'passenger car': 2, 'rail road': 2,\n",
    "    'railroad': 1, 'railway': 1, 'train': 1, 'trains': 1,\n",
    "}\n",
    "\n",
    "LABOR_PATTERNS = {kw: (re.compile(r'\\b' + re.escape(kw) + r'\\b', re.IGNORECASE), w)\n",
    "                  for kw, w in LABOR_KEYWORDS.items()}\n",
    "RAILROAD_PATTERNS = {kw: (re.compile(r'\\b' + re.escape(kw) + r'\\b', re.IGNORECASE), w)\n",
    "                     for kw, w in RAILROAD_KEYWORDS.items()}\n",
    "\n",
    "\n",
    "def best_keyword_position(text, axis):\n",
    "    \"\"\"Find char position of highest-weighted keyword for the given axis.\"\"\"\n",
    "    patterns = LABOR_PATTERNS if axis == 'labor' else RAILROAD_PATTERNS\n",
    "    best_pos, best_weight = 0, 0\n",
    "    for kw, (regex, weight) in patterns.items():\n",
    "        match = regex.search(text)\n",
    "        if match and weight > best_weight:\n",
    "            best_weight = weight\n",
    "            best_pos = match.start()\n",
    "    return best_pos\n",
    "\n",
    "\n",
    "print(\"Keyword patterns loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def smart_truncate(text: str, axis: str, max_length: int = 512) -> str:\n",
    "    \"\"\"\n",
    "    Keyword-centered truncation: keep a token window centered on the\n",
    "    highest-weighted keyword match for this axis.\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    if len(tokens) <= max_length - 2:  # -2 for [CLS] and [SEP]\n",
    "        return text\n",
    "\n",
    "    center_char = best_keyword_position(text, axis)\n",
    "    center_token = int(len(tokens) * center_char / len(text)) if len(text) > 0 else 0\n",
    "\n",
    "    window = max_length - 2\n",
    "    half = window // 2\n",
    "    start = max(0, center_token - half)\n",
    "    end = start + window\n",
    "    if end > len(tokens):\n",
    "        end = len(tokens)\n",
    "        start = max(0, end - window)\n",
    "\n",
    "    return tokenizer.convert_tokens_to_string(tokens[start:end])\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='weighted', zero_division=0\n",
    "    )\n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}\n",
    "\n",
    "\n",
    "print(f\"Tokenizer ready: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(train_path, val_path, label_map, sentiment_key, axis):\n",
    "    \"\"\"Load data, apply keyword-centered truncation, and return HF Datasets.\"\"\"\n",
    "    train_data = load_json(train_path)\n",
    "    val_data = load_json(val_path)\n",
    "    label_names = list(label_map.keys())\n",
    "\n",
    "    print(f\"Training samples: {len(train_data)}\")\n",
    "    print(f\"Validation samples: {len(val_data)}\")\n",
    "\n",
    "    for name, data in [('Train', train_data), ('Val', val_data)]:\n",
    "        print(f\"\\n{name} distribution:\")\n",
    "        for s in label_names:\n",
    "            count = sum(1 for d in data if d.get(sentiment_key) == s)\n",
    "            pct = count / len(data) * 100 if data else 0\n",
    "            print(f\"  {s}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "    human_count = sum(1 for d in train_data if d.get('labeler') == 'human')\n",
    "    gemini_count = sum(1 for d in train_data if d.get('labeler') == 'gemini')\n",
    "    print(f\"\\nTraining labeler mix: {human_count} human, {gemini_count} gemini\")\n",
    "    print(f\"Validation labeler: 100% human ({len(val_data)} samples)\")\n",
    "\n",
    "    # Keyword-centered truncation using the model's axis\n",
    "    train_df = pd.DataFrame([\n",
    "        {'text': smart_truncate(item['text'], axis), 'label': label_map[item[sentiment_key]]}\n",
    "        for item in train_data\n",
    "        if item.get(sentiment_key) in label_map\n",
    "    ])\n",
    "    val_df = pd.DataFrame([\n",
    "        {'text': smart_truncate(item['text'], axis), 'label': label_map[item[sentiment_key]]}\n",
    "        for item in val_data\n",
    "        if item.get(sentiment_key) in label_map\n",
    "    ])\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(train_df).map(tokenize_function, batched=True)\n",
    "    val_dataset = Dataset.from_pandas(val_df).map(tokenize_function, batched=True)\n",
    "\n",
    "    print(f\"\\nTokenized train: {len(train_dataset)}, val: {len(val_dataset)}\")\n",
    "\n",
    "    long_count = sum(1 for item in train_data if len(tokenizer.tokenize(item['text'])) > 510)\n",
    "    print(f\"Articles exceeding 512 tokens (keyword-centered): {long_count}/{len(train_data)} \"\n",
    "          f\"({long_count / len(train_data) * 100:.1f}%)\")\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_dataset, val_dataset, label_map, label_names,\n",
    "                       model_save_dir, model_display_name, axis):\n",
    "    \"\"\"\n",
    "    Train a DistilBERT model, evaluate, print report, save, and free GPU memory.\n",
    "    \"\"\"\n",
    "    id2label = {v: k for k, v in label_map.items()}\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=len(label_map),\n",
    "        id2label=id2label,\n",
    "        label2id=label_map,\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'./results_{model_display_name.replace(\" \", \"_\").lower()}',\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=32,\n",
    "        num_train_epochs=5,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='accuracy',\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        logging_steps=50,\n",
    "        logging_dir=f'./logs_{model_display_name.replace(\" \", \"_\").lower()}',\n",
    "        report_to='none',\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training: {model_display_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Model: {MODEL_NAME}\")\n",
    "    print(f\"  Labels: {label_names}\")\n",
    "    print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
    "    print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
    "    print(f\"  FP16: {training_args.fp16}\")\n",
    "    print(f\"  Truncation: keyword-centered on '{axis}' keywords\")\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate\n",
    "    results = trainer.evaluate()\n",
    "    print(f\"\\n=== {model_display_name} Validation Results (100% hand-labeled) ===\")\n",
    "    print(f\"Accuracy:  {results['eval_accuracy']:.3f}\")\n",
    "    print(f\"Precision: {results['eval_precision']:.3f}\")\n",
    "    print(f\"Recall:    {results['eval_recall']:.3f}\")\n",
    "    print(f\"F1:        {results['eval_f1']:.3f}\")\n",
    "\n",
    "    if results['eval_accuracy'] < 0.60:\n",
    "        print(f\"\\n** WARNING: {model_display_name} accuracy below 60%. Consider:\")\n",
    "        print(\"   - Collapsing to 2-class (biased vs neutral)\")\n",
    "        print(\"   - Increasing hand-labeled training data\")\n",
    "        print(\"   - Switching to RoBERTa-base\")\n",
    "\n",
    "    # Classification report and confusion matrix\n",
    "    predictions = trainer.predict(val_dataset)\n",
    "    y_pred = np.argmax(predictions.predictions, axis=-1)\n",
    "    y_true = np.array(val_dataset['label'])\n",
    "\n",
    "    print(f\"\\n=== Classification Report ===\")\n",
    "    print(classification_report(y_true, y_pred, target_names=label_names))\n",
    "\n",
    "    print(f\"=== Confusion Matrix ===\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    header = ''.join(f'{f\"pred_{n[:5]}\":>12}' for n in label_names)\n",
    "    print(f\"{'':>14}{header}\")\n",
    "    for i, label in enumerate(label_names):\n",
    "        row = ''.join(f'{cm[i][j]:>12}' for j in range(len(label_names)))\n",
    "        print(f\"{label:>14}{row}\")\n",
    "\n",
    "    # Save model\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "    trainer.save_model(model_save_dir)\n",
    "    tokenizer.save_pretrained(model_save_dir)\n",
    "\n",
    "    metadata = {\n",
    "        'model_name': MODEL_NAME,\n",
    "        'display_name': model_display_name,\n",
    "        'axis': axis,\n",
    "        'num_labels': len(label_map),\n",
    "        'label_map': label_map,\n",
    "        'label_names': label_names,\n",
    "        'train_samples': len(train_dataset),\n",
    "        'val_samples': len(val_dataset),\n",
    "        'val_accuracy': results['eval_accuracy'],\n",
    "        'val_f1': results['eval_f1'],\n",
    "        'epochs': int(training_args.num_train_epochs),\n",
    "        'learning_rate': training_args.learning_rate,\n",
    "        'truncation': 'keyword_centered_512',\n",
    "    }\n",
    "    with open(os.path.join(model_save_dir, 'training_metadata.json'), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "\n",
    "    print(f\"\\nModel saved to: {model_save_dir}\")\n",
    "\n",
    "    # Free GPU memory before training next model\n",
    "    del model, trainer\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model A: Labor Stance\n",
    "\n",
    "Trained on labor + both articles. Measures pro-labor vs anti-labor editorial stance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABOR_LABEL_MAP = {'pro_labor': 0, 'anti_labor': 1, 'neutral': 2}\n",
    "LABOR_LABEL_NAMES = ['pro_labor', 'anti_labor', 'neutral']\n",
    "\n",
    "print(\"=== Loading Labor Stance Data ===\")\n",
    "labor_train_ds, labor_val_ds = prepare_dataset(\n",
    "    train_path=os.path.join(DATA_DIR, 'labor_train.json'),\n",
    "    val_path=os.path.join(DATA_DIR, 'labor_val.json'),\n",
    "    label_map=LABOR_LABEL_MAP,\n",
    "    sentiment_key='labor_sentiment',\n",
    "    axis='labor',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labor_results = train_and_evaluate(\n",
    "    train_dataset=labor_train_ds,\n",
    "    val_dataset=labor_val_ds,\n",
    "    label_map=LABOR_LABEL_MAP,\n",
    "    label_names=LABOR_LABEL_NAMES,\n",
    "    model_save_dir=os.path.join(MODEL_BASE_DIR, 'labor_stance_model'),\n",
    "    model_display_name='Labor Stance',\n",
    "    axis='labor',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model B: Railroad Outlook\n",
    "\n",
    "Trained on railroad + both articles. Measures optimism vs pessimism about railroads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAILROAD_LABEL_MAP = {'optimistic': 0, 'pessimistic': 1, 'neutral': 2}\n",
    "RAILROAD_LABEL_NAMES = ['optimistic', 'pessimistic', 'neutral']\n",
    "\n",
    "print(\"=== Loading Railroad Outlook Data ===\")\n",
    "rr_train_ds, rr_val_ds = prepare_dataset(\n",
    "    train_path=os.path.join(DATA_DIR, 'railroad_train.json'),\n",
    "    val_path=os.path.join(DATA_DIR, 'railroad_val.json'),\n",
    "    label_map=RAILROAD_LABEL_MAP,\n",
    "    sentiment_key='railroad_sentiment',\n",
    "    axis='railroad',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "railroad_results = train_and_evaluate(\n",
    "    train_dataset=rr_train_ds,\n",
    "    val_dataset=rr_val_ds,\n",
    "    label_map=RAILROAD_LABEL_MAP,\n",
    "    label_names=RAILROAD_LABEL_NAMES,\n",
    "    model_save_dir=os.path.join(MODEL_BASE_DIR, 'railroad_outlook_model'),\n",
    "    model_display_name='Railroad Outlook',\n",
    "    axis='railroad',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nLabor Stance Model:\")\n",
    "print(f\"  Accuracy: {labor_results['eval_accuracy']:.3f}\")\n",
    "print(f\"  F1:       {labor_results['eval_f1']:.3f}\")\n",
    "print(f\"  Saved to: {os.path.join(MODEL_BASE_DIR, 'labor_stance_model')}\")\n",
    "print(f\"\\nRailroad Outlook Model:\")\n",
    "print(f\"  Accuracy: {railroad_results['eval_accuracy']:.3f}\")\n",
    "print(f\"  F1:       {railroad_results['eval_f1']:.3f}\")\n",
    "print(f\"  Saved to: {os.path.join(MODEL_BASE_DIR, 'railroad_outlook_model')}\")\n",
    "\n",
    "both_ok = labor_results['eval_accuracy'] >= 0.60 and railroad_results['eval_accuracy'] >= 0.60\n",
    "print(f\"\\nBoth models >= 60% accuracy: {'YES' if both_ok else 'NO -- consider 2-class fallback below'}\")\n",
    "print(f\"\\nNext step: Run 04_sentiment_inference.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
