{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "927ee80b",
   "metadata": {},
   "source": [
    "###  Estimating the effect of new editors/owners on Newspaper Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3154e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samwt\\AppData\\Local\\Temp\\ipykernel_20012\\3145179763.py:10: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/Archive/master.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PUBLISHER & EDITOR CHANGE ANALYSIS RESULTS\n",
      "============================================================\n",
      "\n",
      "Total newspapers analyzed: 47956\n",
      "Newspapers with at least 4 years of data: 12397\n",
      "Newspapers with insufficient data: 35559\n",
      "\n",
      "----------------------------------------\n",
      "CATEGORY BREAKDOWN:\n",
      "----------------------------------------\n",
      "Editor & publisher changed (same year): 5014 (40.4%)\n",
      "Editor & publisher changed (diff years): 851 (6.9%)\n",
      "Publisher changed only: 794 (6.4%)\n",
      "Editor changed only: 674 (5.4%)\n",
      "No change detected: 5064 (40.8%)\n",
      "\n",
      "============================================================\n",
      "Updated master.csv with 'category', 'publisher_change_year', and 'editor_change_year' columns\n",
      "============================================================\n",
      "\n",
      "----------------------------------------\n",
      "SAMPLE: Newspapers with changes\n",
      "----------------------------------------\n",
      "state      town     newspaper_name                              category  publisher_change_year  editor_change_year\n",
      "  NaN  Abingdon  Knox Co. Democrat                 publisher_change_only                 1872.0                 NaN\n",
      "  NaN     Afton            Tribane editor_and_publisher_change_same_year                 1876.0              1876.0\n",
      "  NaN     Albia Spirit of the West editor_and_publisher_change_same_year                 1872.0              1872.0\n",
      "  NaN    Albion            Pioneer                 publisher_change_only                 1872.0                 NaN\n",
      "  NaN     Aledo  Democratic Banner editor_and_publisher_change_same_year                 1872.0              1872.0\n",
      "  NaN Allentown Lehigh Valley News                    editor_change_only                    NaN              1871.0\n",
      "  NaN Allentown Stadtand Land-Bote                    editor_change_only                    NaN              1871.0\n",
      "  NaN  Alliance              Local editor_and_publisher_change_same_year                 1872.0              1872.0\n",
      "  NaN  Angelica         Republican editor_and_publisher_change_same_year                 1876.0              1876.0\n",
      "  NaN Ann Arbor Peninsular Courier                    editor_change_only                    NaN              1871.0\n",
      "\n",
      "============================================================\n",
      "DataFrames created:\n",
      "  - publisher_change_only_list\n",
      "  - editor_change_only_list\n",
      "  - editor_and_publisher_same_list\n",
      "  - editor_and_publisher_diff_list\n",
      "  - no_change_list\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# add publisher and editor change information to Master.csv\n",
    "# NOW SPLITS editor_and_publisher_change into:\n",
    "#   - editor_and_publisher_change_same_year\n",
    "#   - editor_and_publisher_change_diff_year\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('data/master.csv')\n",
    "\n",
    "# Define the years we're tracking\n",
    "years = [1869, 1871, 1872, 1873, 1876, 1877, 1878, 1879, 1880, 1882, 1883, 1884, 1885, 1890]\n",
    "\n",
    "def levenshtein_distance(s1, s2):\n",
    "    \"\"\"Calculate the Levenshtein distance between two strings.\"\"\"\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    prev_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        curr_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = prev_row[j + 1] + 1\n",
    "            deletions = curr_row[j] + 1\n",
    "            substitutions = prev_row[j] + (c1 != c2)\n",
    "            curr_row.append(min(insertions, deletions, substitutions))\n",
    "        prev_row = curr_row\n",
    "    return prev_row[-1]\n",
    "\n",
    "def strings_match(s1, s2, max_distance=1):\n",
    "    \"\"\"Check if two strings match within max_distance edits.\"\"\"\n",
    "    s1_clean = s1.strip().lower()\n",
    "    s2_clean = s2.strip().lower()\n",
    "    if s1_clean == s2_clean:\n",
    "        return True\n",
    "    return levenshtein_distance(s1_clean, s2_clean) <= max_distance\n",
    "\n",
    "def tokenize_publisher(publisher_str):\n",
    "    if not publisher_str:\n",
    "        return []\n",
    "    cleaned = re.sub(r'[;,]', ' ', publisher_str)\n",
    "    tokens = cleaned.split()\n",
    "    return [t.strip() for t in tokens if len(t.strip()) >= 4]\n",
    "\n",
    "def publishers_match_tokenized(pub1, pub2):\n",
    "    tokens1 = tokenize_publisher(pub1)\n",
    "    tokens2 = tokenize_publisher(pub2)\n",
    "    if not tokens1 or not tokens2:\n",
    "        return False\n",
    "    for t1 in tokens1:\n",
    "        for t2 in tokens2:\n",
    "            if strings_match(t1, t2, max_distance=1):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def normalize_publisher(pub):\n",
    "    if not pub:\n",
    "        return \"\"\n",
    "    return re.sub(r'[^a-z0-9]', '', pub.lower())\n",
    "\n",
    "def publishers_match_normalized(pub1, pub2):\n",
    "    n1 = normalize_publisher(pub1)\n",
    "    n2 = normalize_publisher(pub2)\n",
    "    if not n1 or not n2:\n",
    "        return False\n",
    "    return n1 == n2 or n1 in n2 or n2 in n1\n",
    "\n",
    "def names_match(name1, name2):\n",
    "    return publishers_match_tokenized(name1, name2) or publishers_match_normalized(name1, name2)\n",
    "\n",
    "def clean_field(value):\n",
    "    if pd.isna(value):\n",
    "        return ''\n",
    "    s = str(value).strip()\n",
    "    if s.lower() == 'nan':\n",
    "        return ''\n",
    "    return s\n",
    "\n",
    "def detect_first_change(data_points):\n",
    "    for i in range(1, len(data_points)):\n",
    "        prev_year, prev_val = data_points[i - 1]\n",
    "        curr_year, curr_val = data_points[i]\n",
    "        if not names_match(prev_val, curr_val):\n",
    "            return curr_year\n",
    "    return None\n",
    "\n",
    "def analyze_changes(row):\n",
    "    \"\"\"\n",
    "    Analyze a newspaper row for publisher and editor changes.\n",
    "    Returns: (category, publisher_change_year, editor_change_year)\n",
    "    Categories:\n",
    "      - 'insufficient_data'\n",
    "      - 'no_change'\n",
    "      - 'publisher_change_only'\n",
    "      - 'editor_change_only'\n",
    "      - 'editor_and_publisher_change_same_year'   <-- NEW\n",
    "      - 'editor_and_publisher_change_diff_year'   <-- NEW\n",
    "    \"\"\"\n",
    "    pub_data = []\n",
    "    ed_data = []\n",
    "    for year in years:\n",
    "        publisher = clean_field(row.get(f'{year} publisher', ''))\n",
    "        editor = clean_field(row.get(f'{year} editor', ''))\n",
    "        if publisher:\n",
    "            pub_data.append((year, publisher))\n",
    "        if editor:\n",
    "            ed_data.append((year, editor))\n",
    "\n",
    "    has_enough_pub = len(pub_data) >= 3\n",
    "    has_enough_ed = len(ed_data) >= 3\n",
    "\n",
    "    if not has_enough_pub and not has_enough_ed:\n",
    "        return ('insufficient_data', None, None)\n",
    "\n",
    "    pub_change_year = detect_first_change(pub_data) if has_enough_pub else None\n",
    "    ed_change_year = detect_first_change(ed_data) if has_enough_ed else None\n",
    "\n",
    "    has_pub_change = pub_change_year is not None\n",
    "    has_ed_change = ed_change_year is not None\n",
    "\n",
    "    if has_pub_change and has_ed_change:\n",
    "        if pub_change_year == ed_change_year:\n",
    "            category = 'editor_and_publisher_change_same_year'\n",
    "        else:\n",
    "            category = 'editor_and_publisher_change_diff_year'\n",
    "    elif has_pub_change:\n",
    "        category = 'publisher_change_only'\n",
    "    elif has_ed_change:\n",
    "        category = 'editor_change_only'\n",
    "    else:\n",
    "        category = 'no_change'\n",
    "\n",
    "    return (category, pub_change_year, ed_change_year)\n",
    "\n",
    "# Apply analysis to each row\n",
    "results = df.apply(analyze_changes, axis=1)\n",
    "df['category'] = results.apply(lambda x: x[0])\n",
    "df['publisher_change_year'] = results.apply(lambda x: x[1])\n",
    "df['editor_change_year'] = results.apply(lambda x: x[2])\n",
    "\n",
    "# Filter out insufficient data\n",
    "valid_df = df[df['category'] != 'insufficient_data'].copy()\n",
    "\n",
    "# Count categories\n",
    "category_counts = valid_df['category'].value_counts()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PUBLISHER & EDITOR CHANGE ANALYSIS RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal newspapers analyzed: {len(df)}\")\n",
    "print(f\"Newspapers with at least 4 years of data: {len(valid_df)}\")\n",
    "print(f\"Newspapers with insufficient data: {len(df) - len(valid_df)}\")\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "print(\"CATEGORY BREAKDOWN:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "category_labels = {\n",
    "    'editor_and_publisher_change_same_year': 'Editor & publisher changed (same year)',\n",
    "    'editor_and_publisher_change_diff_year': 'Editor & publisher changed (diff years)',\n",
    "    'publisher_change_only': 'Publisher changed only',\n",
    "    'editor_change_only': 'Editor changed only',\n",
    "    'no_change': 'No change detected',\n",
    "}\n",
    "\n",
    "for cat, label in category_labels.items():\n",
    "    count = category_counts.get(cat, 0)\n",
    "    pct = (count / len(valid_df) * 100) if len(valid_df) > 0 else 0\n",
    "    print(f\"{label}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# Save updated CSV\n",
    "df.to_csv('data/master.csv', index=False)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Updated master.csv with 'category', 'publisher_change_year', and 'editor_change_year' columns\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show sample of newspapers with changes\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "print(\"SAMPLE: Newspapers with changes\")\n",
    "print(\"-\" * 40)\n",
    "change_categories = list(category_labels.keys())\n",
    "change_categories.remove('no_change')\n",
    "changes_df = valid_df[valid_df['category'].isin(change_categories)]\n",
    "if len(changes_df) > 0:\n",
    "    sample_cols = ['state', 'town', 'newspaper_name', 'category', 'publisher_change_year', 'editor_change_year']\n",
    "    print(changes_df[sample_cols].head(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"No changes found.\")\n",
    "\n",
    "# Create lists for each category\n",
    "publisher_change_only_list = valid_df[valid_df['category'] == 'publisher_change_only'][\n",
    "    ['state', 'town', 'newspaper_name', 'publisher_change_year']\n",
    "]\n",
    "editor_change_only_list = valid_df[valid_df['category'] == 'editor_change_only'][\n",
    "    ['state', 'town', 'newspaper_name', 'editor_change_year']\n",
    "]\n",
    "editor_and_publisher_same_list = valid_df[valid_df['category'] == 'editor_and_publisher_change_same_year'][\n",
    "    ['state', 'town', 'newspaper_name', 'publisher_change_year', 'editor_change_year']\n",
    "]\n",
    "editor_and_publisher_diff_list = valid_df[valid_df['category'] == 'editor_and_publisher_change_diff_year'][\n",
    "    ['state', 'town', 'newspaper_name', 'publisher_change_year', 'editor_change_year']\n",
    "]\n",
    "no_change_list = valid_df[valid_df['category'] == 'no_change'][\n",
    "    ['state', 'town', 'newspaper_name']\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DataFrames created:\")\n",
    "print(\"  - publisher_change_only_list\")\n",
    "print(\"  - editor_change_only_list\")\n",
    "print(\"  - editor_and_publisher_same_list\")\n",
    "print(\"  - editor_and_publisher_diff_list\")\n",
    "print(\"  - no_change_list\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdaef444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samwt\\AppData\\Local\\Temp\\ipykernel_14920\\1763648295.py:5: DtypeWarning: Columns (10,96) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  master = pd.read_csv(\"data/master.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with master_id: 521\n",
      "Rows with publisher_change_year: 242\n",
      "28\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "# filter down to newspapers that we can match \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "master = pd.read_csv(\"data/master.csv\")\n",
    "matches = pd.read_csv(\"data/matches.csv\")\n",
    "\n",
    "matches[\"publisher_change_year\"] = matches[\"master_id\"].dropna().astype(int).map(master[\"publisher_change_year\"])\n",
    "matches[\"editor_change_year\"] = matches[\"master_id\"].dropna().astype(int).map(master[\"editor_change_year\"])\n",
    "matches[\"category\"] = matches[\"master_id\"].dropna().astype(int).map(master[\"category\"])\n",
    "matches = matches[matches.master_id.notna()]\n",
    "matches.to_csv(\"data/final_list.csv\", index=False)\n",
    "\n",
    "print(f\"Rows with master_id: {matches['master_id'].notna().sum()}\")\n",
    "print(f\"Rows with publisher_change_year: {matches['publisher_change_year'].notna().sum()}\")\n",
    "\n",
    "print(len(matches[matches.category.str.contains('editor_change_only')]))\n",
    "print(len(matches[matches.category.str.contains('publisher_change_only')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea998b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 27 diff-year papers from panel\n",
      "Median treatment year among treated papers: 1876.0\n",
      "Papers with ≥3 pre-treatment years: 325\n",
      "\n",
      "Sample of final panel:\n",
      "\n",
      " Newspaper_ID                               Newspaper_Name  Year          category  is_treated  Anchor_Cutoff_Year  Post_it       Y_it  Rel_Year  is_publisher_change_only  is_editor_change_only  is_editor_and_publisher_change_same_year  Post_x_publisher_change_only  Post_x_editor_change_only  Post_x_editor_and_publisher_change_same_year\n",
      "          4.0 Meridional.tt ALEXANDRIA, Louisiana Democrat  1877 insufficient_data       False                1883        0  42.951005        -6                         0                      0                                         0                             0                          0                                             0\n",
      "          4.0 Meridional.tt ALEXANDRIA, Louisiana Democrat  1878 insufficient_data       False                1883        0  11.705858        -5                         0                      0                                         0                             0                          0                                             0\n",
      "          4.0 Meridional.tt ALEXANDRIA, Louisiana Democrat  1879 insufficient_data       False                1883        0  17.509141        -4                         0                      0                                         0                             0                          0                                             0\n",
      "          4.0 Meridional.tt ALEXANDRIA, Louisiana Democrat  1880 insufficient_data       False                1883        0  19.699659        -3                         0                      0                                         0                             0                          0                                             0\n",
      "          4.0 Meridional.tt ALEXANDRIA, Louisiana Democrat  1881 insufficient_data       False                1883        0  26.164697        -2                         0                      0                                         0                             0                          0                                             0\n",
      "          4.0 Meridional.tt ALEXANDRIA, Louisiana Democrat  1882 insufficient_data       False                1883        0  20.727700        -1                         0                      0                                         0                             0                          0                                             0\n",
      "          4.0 Meridional.tt ALEXANDRIA, Louisiana Democrat  1883 insufficient_data       False                1883        1  30.203680         0                         0                      0                                         0                             0                          0                                             0\n",
      "          4.0 Meridional.tt ALEXANDRIA, Louisiana Democrat  1884 insufficient_data       False                1883        1  45.615109         1                         0                      0                                         0                             0                          0                                             0\n",
      "          4.0 Meridional.tt ALEXANDRIA, Louisiana Democrat  1885 insufficient_data       False                1883        1  73.492058         2                         0                      0                                         0                             0                          0                                             0\n",
      "          4.0 Meridional.tt ALEXANDRIA, Louisiana Democrat  1886 insufficient_data       False                1883        1  73.771808         3                         0                      0                                         0                             0                          0                                             0\n",
      "          4.0 Meridional.tt ALEXANDRIA, Louisiana Democrat  1887 insufficient_data       False                1883        1  53.730919         4                         0                      0                                         0                             0                          0                                             0\n",
      "          4.0 Meridional.tt ALEXANDRIA, Louisiana Democrat  1888 insufficient_data       False                1883        1  69.718602         5                         0                      0                                         0                             0                          0                                             0\n",
      "          4.0 Meridional.tt ALEXANDRIA, Louisiana Democrat  1889 insufficient_data       False                1883        1 100.624361         6                         0                      0                                         0                             0                          0                                             0\n",
      "          4.0 Meridional.tt ALEXANDRIA, Louisiana Democrat  1890 insufficient_data       False                1883        1  58.227718         7                         0                      0                                         0                             0                          0                                             0\n",
      "       3330.0                            St. Mary's Beacon  1869         no_change       False                1879        0  28.901848       -10                         0                      0                                         0                             0                          0                                             0\n",
      "       3330.0                            St. Mary's Beacon  1870         no_change       False                1879        0  31.289667        -9                         0                      0                                         0                             0                          0                                             0\n",
      "       3330.0                            St. Mary's Beacon  1871         no_change       False                1879        0  24.693600        -8                         0                      0                                         0                             0                          0                                             0\n",
      "       3330.0                            St. Mary's Beacon  1872         no_change       False                1879        0  30.924282        -7                         0                      0                                         0                             0                          0                                             0\n",
      "       3330.0                            St. Mary's Beacon  1873         no_change       False                1879        0  17.883405        -6                         0                      0                                         0                             0                          0                                             0\n",
      "       3330.0                            St. Mary's Beacon  1874         no_change       False                1879        0  16.311888        -5                         0                      0                                         0                             0                          0                                             0\n",
      "\n",
      "--- Panel Summary ---\n",
      "Total observations: 3543\n",
      "Unique newspapers: 325\n",
      "Control papers (no_change): 218\n",
      "Treated papers (publisher_change_only): 26\n",
      "Treated papers (editor_change_only): 11\n",
      "Treated papers (editor_and_publisher_change_same_year): 70\n",
      "Pre-treatment obs: 1760\n",
      "Post-treatment obs: 1783\n",
      "\n",
      "Saved to 'panel_structural_drift.csv'\n"
     ]
    }
   ],
   "source": [
    "# structural drift panel creation — multi-treatment DID\n",
    "# Updated: uses editor_and_publisher_change_same_year only\n",
    "#          (drops editor_and_publisher_change_diff_year observations)\n",
    "# Updated: topic_counts keyed by issn\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Load data sources\n",
    "newspapers = pd.read_csv('data/final_list.csv')\n",
    "with open('data/topic_counts.json', 'r') as f:\n",
    "    topic_data = json.load(f)\n",
    "\n",
    "TOPICS = [\n",
    "    'labor_workers', 'politics_elections', 'congress_government',\n",
    "    'business_commerce', 'railroads_transportation', 'agriculture_farming',\n",
    "    'courts_law', 'finance_money', 'immigration_foreign', 'crime_police'\n",
    "]\n",
    "\n",
    "# Only these three categories are treated; diff-year papers are excluded entirely\n",
    "TREATMENT_CATEGORIES = [\n",
    "    'publisher_change_only',\n",
    "    'editor_change_only',\n",
    "    'editor_and_publisher_change_same_year',\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1: Build raw panel with topic rates per 1,000 headlines\n",
    "# =============================================================================\n",
    "records = []\n",
    "for year, papers in topic_data.items():\n",
    "    for issn, data in papers.items():\n",
    "        if 'topic_counts' in data and 'total_headlines' in data:\n",
    "            total = data['total_headlines']\n",
    "            if total >= 75:\n",
    "                record = {\n",
    "                    'year': int(year),\n",
    "                    'issn': issn\n",
    "                }\n",
    "                for topic in TOPICS:\n",
    "                    count = data['topic_counts'].get(topic, 0)\n",
    "                    record[topic] = (count / total) * 1000\n",
    "                records.append(record)\n",
    "\n",
    "panel = pd.DataFrame(records)\n",
    "\n",
    "# Merge with metadata\n",
    "panel = panel.merge(\n",
    "    newspapers[[\n",
    "        'issn', 'master_id', 'master_name',\n",
    "        'category', 'publisher_change_year', 'editor_change_year'\n",
    "    ]],\n",
    "    on='issn', how='left'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1.5: Drop diff-year papers entirely so they don't pollute control group\n",
    "# =============================================================================\n",
    "n_before = panel['master_id'].nunique()\n",
    "panel = panel[panel['category'] != 'editor_and_publisher_change_diff_year'].copy()\n",
    "n_after = panel['master_id'].nunique()\n",
    "print(f\"Dropped {n_before - n_after} diff-year papers from panel\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2: Determine treatment status and treatment year per paper\n",
    "# =============================================================================\n",
    "panel['is_treated'] = panel['category'].isin(TREATMENT_CATEGORIES)\n",
    "\n",
    "def get_treatment_year(row):\n",
    "    \"\"\"Return the earliest change year for a treated paper, or NaN for control.\"\"\"\n",
    "    if row['category'] not in TREATMENT_CATEGORIES:\n",
    "        return np.nan\n",
    "    years = []\n",
    "    if pd.notna(row['publisher_change_year']):\n",
    "        years.append(row['publisher_change_year'])\n",
    "    if pd.notna(row['editor_change_year']):\n",
    "        years.append(row['editor_change_year'])\n",
    "    return min(years) if years else np.nan\n",
    "\n",
    "panel['treatment_year'] = panel.apply(get_treatment_year, axis=1)\n",
    "\n",
    "# Adjust: subtract 1 so the treatment year marks the last pre-treatment year\n",
    "panel['treatment_year'] = panel['treatment_year'] - 1\n",
    "\n",
    "median_treat_year = panel.loc[panel['is_treated'], 'treatment_year'].median()\n",
    "\n",
    "print(f\"Median treatment year among treated papers: \"\n",
    "      f\"{panel.loc[panel['is_treated'], 'treatment_year'].median()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 3: Create treatment group dummies\n",
    "# =============================================================================\n",
    "for cat in TREATMENT_CATEGORIES:\n",
    "    panel[f'is_{cat}'] = (panel['category'] == cat).astype(int)\n",
    "\n",
    "# =============================================================================\n",
    "# Step 4: Define anchor cutoff year for each paper\n",
    "#         Treated  → treatment_year (already set above)\n",
    "#         Control  → max(first_year + 3, individual median year)\n",
    "# =============================================================================\n",
    "panel = panel.dropna(subset=['master_id']).copy()\n",
    "paper_stats = panel.groupby('master_id')['year'].agg(['min', 'median'])\n",
    "paper_stats.columns = ['first_year', 'median_year']\n",
    "panel = panel.merge(paper_stats, on='master_id', how='left')\n",
    "\n",
    "panel['anchor_cutoff'] = np.where(\n",
    "    panel['is_treated'],\n",
    "    panel['treatment_year'],\n",
    "    np.maximum(panel['first_year'] + 3, panel['median_year'])\n",
    ").astype(int)\n",
    "\n",
    "panel.drop(columns=['first_year', 'median_year'], inplace=True)\n",
    "\n",
    "# =============================================================================\n",
    "# Step 5: Filter papers with at least 3 pre-treatment years\n",
    "# =============================================================================\n",
    "pre_counts = panel[panel['year'] < panel['anchor_cutoff']].groupby('master_id').size()\n",
    "valid_papers = pre_counts[pre_counts >= 3].index\n",
    "panel = panel[panel['master_id'].isin(valid_papers)].copy()\n",
    "print(f\"Papers with ≥3 pre-treatment years: {len(valid_papers)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 6: Calculate anchor vector (pre-treatment average) for each paper\n",
    "# =============================================================================\n",
    "pre_panel = panel[panel['year'] < panel['anchor_cutoff']]\n",
    "anchors = pre_panel.groupby('master_id')[TOPICS].mean()\n",
    "anchors.columns = [f'anchor_{t}' for t in TOPICS]\n",
    "\n",
    "panel = panel.merge(anchors, on='master_id', how='left')\n",
    "\n",
    "# =============================================================================\n",
    "# Step 7: Calculate Y_it = Euclidean distance from anchor\n",
    "# =============================================================================\n",
    "def calc_drift(row):\n",
    "    sq_diffs = sum((row[t] - row[f'anchor_{t}'])**2 for t in TOPICS)\n",
    "    return np.sqrt(sq_diffs)\n",
    "\n",
    "panel['Y_it'] = panel.apply(calc_drift, axis=1)\n",
    "\n",
    "# =============================================================================\n",
    "# Step 8: Create Post_it dummy and interaction terms\n",
    "# =============================================================================\n",
    "panel['Post_it'] = (panel['year'] >= panel['anchor_cutoff']).astype(int)\n",
    "\n",
    "for cat in TREATMENT_CATEGORIES:\n",
    "    panel[f'Post_x_{cat}'] = panel['Post_it'] * panel[f'is_{cat}']\n",
    "\n",
    "# =============================================================================\n",
    "# Step 9: Event-study relative time variable\n",
    "# =============================================================================\n",
    "panel['rel_year'] = panel['year'] - panel['anchor_cutoff']\n",
    "\n",
    "# =============================================================================\n",
    "# Step 10: Build final output table\n",
    "# =============================================================================\n",
    "output_cols = [\n",
    "    'master_id', 'master_name', 'year', 'category',\n",
    "    'is_treated', 'anchor_cutoff', 'Post_it', 'Y_it', 'rel_year',\n",
    "] + [f'is_{cat}' for cat in TREATMENT_CATEGORIES] \\\n",
    "  + [f'Post_x_{cat}' for cat in TREATMENT_CATEGORIES]\n",
    "\n",
    "output = panel[output_cols].rename(columns={\n",
    "    'master_id': 'Newspaper_ID',\n",
    "    'master_name': 'Newspaper_Name',\n",
    "    'year': 'Year',\n",
    "    'anchor_cutoff': 'Anchor_Cutoff_Year',\n",
    "    'rel_year': 'Rel_Year',\n",
    "}).sort_values(['Newspaper_ID', 'Year']).reset_index(drop=True)\n",
    "\n",
    "# Display diagnostics\n",
    "print(\"\\nSample of final panel:\\n\")\n",
    "print(output.head(20).to_string(index=False))\n",
    "\n",
    "print(f\"\\n--- Panel Summary ---\")\n",
    "print(f\"Total observations: {len(output)}\")\n",
    "print(f\"Unique newspapers: {output['Newspaper_ID'].nunique()}\")\n",
    "\n",
    "treated_counts = panel[panel['is_treated']].groupby('category')['master_id'].nunique()\n",
    "control_count = panel[~panel['is_treated']]['master_id'].nunique()\n",
    "print(f\"Control papers (no_change): {control_count}\")\n",
    "for cat in TREATMENT_CATEGORIES:\n",
    "    count = treated_counts.get(cat, 0)\n",
    "    print(f\"Treated papers ({cat}): {count}\")\n",
    "\n",
    "print(f\"Pre-treatment obs: {(output['Post_it'] == 0).sum()}\")\n",
    "print(f\"Post-treatment obs: {(output['Post_it'] == 1).sum()}\")\n",
    "\n",
    "# Save\n",
    "output.to_csv('data/panel_structural_drift.csv', index=False)\n",
    "print(\"\\nSaved to 'panel_structural_drift.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
