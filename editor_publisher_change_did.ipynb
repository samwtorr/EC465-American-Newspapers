{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "927ee80b",
   "metadata": {},
   "source": [
    "###  Estimating the effect of new editors/owners on Newspaper Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea998b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structural drift panel creation\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Load data sources\n",
    "newspapers = pd.read_csv('data/final_list.csv')\n",
    "with open('data/topic_counts.json', 'r') as f:\n",
    "    topic_data = json.load(f)\n",
    "\n",
    "TOPICS = [\n",
    "    'labor_workers', 'politics_elections', 'congress_government',\n",
    "    'business_commerce', 'railroads_transportation', 'agriculture_farming',\n",
    "    'courts_law', 'finance_money', 'immigration_foreign', 'crime_police'\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1: Build raw panel with topic rates per 1,000 headlines\n",
    "# =============================================================================\n",
    "records = []\n",
    "for year, papers in topic_data.items():\n",
    "    for paper_name, data in papers.items():\n",
    "        if 'topic_counts' in data and 'total_headlines' in data:\n",
    "            total = data['total_headlines']\n",
    "            if total > 0:\n",
    "                record = {\n",
    "                    'year': int(year),\n",
    "                    'newspapers_all_years_name': paper_name.lower().strip()\n",
    "                }\n",
    "                for topic in TOPICS:\n",
    "                    count = data['topic_counts'].get(topic, 0)\n",
    "                    record[topic] = (count / total) * 1000\n",
    "                records.append(record)\n",
    "\n",
    "panel = pd.DataFrame(records)\n",
    "\n",
    "# Merge with metadata\n",
    "newspapers['newspapers_all_years_name'] = newspapers['newspapers_all_years_name'].str.lower().str.strip()\n",
    "panel = panel.merge(\n",
    "    newspapers[['newspapers_all_years_name', 'master_id', 'master_name', 'publisher_change_year']],\n",
    "    on='newspapers_all_years_name', how='left'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2: Identify treated vs control; find median treatment year\n",
    "# Correct treatment year by subtracting 1\n",
    "# =============================================================================\n",
    "panel['is_treated'] = panel['publisher_change_year'].notna()\n",
    "panel['publisher_change_year'] = panel['publisher_change_year'] - 1\n",
    "median_treat_year = panel.loc[panel['is_treated'], 'publisher_change_year'].median()\n",
    "print(f\"Median treatment year among treated papers: {median_treat_year}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 3: Define anchor cutoff year for each paper\n",
    "# Treated: their specific treatment year\n",
    "# Control: the median treatment year\n",
    "# =============================================================================\n",
    "panel['anchor_cutoff'] = np.where(\n",
    "    panel['is_treated'],\n",
    "    panel['publisher_change_year'],\n",
    "    median_treat_year\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 4: Filter papers with at least 3 pre-treatment years\n",
    "# (using the ADJUSTED anchor cutoff)\n",
    "# =============================================================================\n",
    "pre_counts = panel[panel['year'] < panel['anchor_cutoff']].groupby('master_id').size()\n",
    "valid_papers = pre_counts[pre_counts >= 3].index\n",
    "panel = panel[panel['master_id'].isin(valid_papers)].copy()\n",
    "print(f\"Papers with ≥3 pre-treatment years (adjusted): {len(valid_papers)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 5: Calculate anchor vector (pre-treatment average) for each paper\n",
    "# Using the ADJUSTED cutoff\n",
    "# =============================================================================\n",
    "pre_panel = panel[panel['year'] < panel['anchor_cutoff']]\n",
    "anchors = pre_panel.groupby('master_id')[TOPICS].mean()\n",
    "anchors.columns = [f'anchor_{t}' for t in TOPICS]\n",
    "\n",
    "panel = panel.merge(anchors, on='master_id', how='left')\n",
    "\n",
    "# =============================================================================\n",
    "# Step 6: Calculate Y_it = Euclidean distance from anchor\n",
    "# =============================================================================\n",
    "def calc_drift(row):\n",
    "    sq_diffs = sum((row[t] - row[f'anchor_{t}'])**2 for t in TOPICS)\n",
    "    return np.sqrt(sq_diffs)\n",
    "\n",
    "panel['Y_it'] = panel.apply(calc_drift, axis=1)\n",
    "\n",
    "# =============================================================================\n",
    "# Step 7: Create Post_it dummy (relative to ADJUSTED anchor cutoff)\n",
    "# =============================================================================\n",
    "panel['Post_it'] = (panel['year'] >= panel['anchor_cutoff']).astype(int)\n",
    "\n",
    "# =============================================================================\n",
    "# Step 8: Build final output table\n",
    "# =============================================================================\n",
    "output = panel[[\n",
    "    'master_id', 'master_name', 'year', 'is_treated', \n",
    "    'anchor_cutoff', 'Post_it', 'Y_it'\n",
    "]].rename(columns={\n",
    "    'master_id': 'Newspaper_ID',\n",
    "    'master_name': 'Newspaper_Name',\n",
    "    'year': 'Year',\n",
    "    'anchor_cutoff': 'Anchor_Cutoff_Year'\n",
    "}).sort_values(['Newspaper_ID', 'Year']).reset_index(drop=True)\n",
    "\n",
    "# Display diagnostics\n",
    "print(\"\\nSample of final panel:\\n\")\n",
    "print(output.head(20).to_string(index=False))\n",
    "\n",
    "print(f\"\\n--- Panel Summary ---\")\n",
    "print(f\"Total observations: {len(output)}\")\n",
    "print(f\"Unique newspapers: {output['Newspaper_ID'].nunique()}\")\n",
    "print(f\"Treated papers: {output[output['is_treated']]['Newspaper_ID'].nunique()}\")\n",
    "print(f\"Control papers: {output[~output['is_treated']]['Newspaper_ID'].nunique()}\")\n",
    "print(f\"Pre-treatment obs: {(output['Post_it'] == 0).sum()}\")\n",
    "print(f\"Post-treatment obs: {(output['Post_it'] == 1).sum()}\")\n",
    "\n",
    "# Save\n",
    "output.to_csv('data/panel_structural_drift.csv', index=False)\n",
    "print(\"\\nSaved to 'panel_structural_drift.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf47fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the structural drift panel\n",
    "panel = pd.read_csv('data/panel_structural_drift.csv')\n",
    "\n",
    "# =============================================================================\n",
    "# Model 1: Static DiD\n",
    "# Y_it = α_i + δ_t + β(Post_it) + ε_it\n",
    "# Tests: Did treated papers drift further from baseline than controls?\n",
    "# =============================================================================\n",
    "reg_data = panel[['Newspaper_ID', 'Year', 'Post_it', 'Y_it', 'is_treated']].dropna()\n",
    "\n",
    "static_model = smf.ols(\n",
    "    'Y_it ~ Post_it + C(Newspaper_ID) + C(Year)',\n",
    "    data=reg_data\n",
    ").fit(cov_type='cluster', cov_kwds={'groups': reg_data['Newspaper_ID']})\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL 1: STATIC DiD — Average Treatment Effect on Structural Drift\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nβ (Post_it):     {static_model.params['Post_it']:.4f}\")\n",
    "print(f\"Std Error:       {static_model.bse['Post_it']:.4f}\")\n",
    "print(f\"95% CI:          [{static_model.conf_int().loc['Post_it', 0]:.4f}, {static_model.conf_int().loc['Post_it', 1]:.4f}]\")\n",
    "print(f\"P-value:         {static_model.pvalues['Post_it']:.4f}\")\n",
    "print(f\"R-squared:       {static_model.rsquared:.4f}\")\n",
    "print(f\"Observations:    {static_model.nobs:.0f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Model 2: Event Study (Dynamic Effects)\n",
    "# Y_it = α_i + δ_t + Σ β_k D^k_it + ε_it\n",
    "# Shows timing of drift: immediate vs gradual?\n",
    "# =============================================================================\n",
    "K_MIN, K_MAX = -5, 5\n",
    "\n",
    "# Calculate time relative to anchor cutoff\n",
    "panel['Time_to_Treat'] = panel['Year'] - panel['Anchor_Cutoff_Year']\n",
    "\n",
    "def bin_time(k):\n",
    "    if pd.isna(k): return None\n",
    "    if k < K_MIN: return f'k_{K_MIN}'\n",
    "    if k > K_MAX: return f'k_{K_MAX}'\n",
    "    return f'k_{int(k)}'\n",
    "\n",
    "panel['event_time'] = panel['Time_to_Treat'].apply(bin_time)\n",
    "panel['event_time'] = pd.Categorical(\n",
    "    panel['event_time'],\n",
    "    categories=[f'k_{k}' for k in range(K_MIN, K_MAX + 1)]\n",
    ")\n",
    "\n",
    "reg_data_es = panel[['Newspaper_ID', 'Year', 'event_time', 'Y_it']].dropna()\n",
    "\n",
    "event_model = smf.ols(\n",
    "    'Y_it ~ C(event_time, Treatment(\"k_-1\")) + C(Newspaper_ID) + C(Year)',\n",
    "    data=reg_data_es\n",
    ").fit(cov_type='cluster', cov_kwds={'groups': reg_data_es['Newspaper_ID']})\n",
    "\n",
    "# Extract coefficients for plotting\n",
    "coefs = []\n",
    "for k in range(K_MIN, K_MAX + 1):\n",
    "    if k == -1:\n",
    "        coefs.append({'k': k, 'beta': 0, 'ci_low': 0, 'ci_high': 0, 'pval': np.nan})\n",
    "    else:\n",
    "        param = f'C(event_time, Treatment(\"k_-1\"))[T.k_{k}]'\n",
    "        if param in event_model.params:\n",
    "            coefs.append({\n",
    "                'k': k,\n",
    "                'beta': event_model.params[param],\n",
    "                'ci_low': event_model.conf_int().loc[param, 0],\n",
    "                'ci_high': event_model.conf_int().loc[param, 1],\n",
    "                'pval': event_model.pvalues[param]\n",
    "            })\n",
    "\n",
    "coef_df = pd.DataFrame(coefs)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL 2: EVENT STUDY — Dynamic Path of Structural Drift\")\n",
    "print(\"=\" * 70)\n",
    "print(coef_df.to_string(index=False, float_format='{:.4f}'.format))\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.errorbar(coef_df['k'], coef_df['beta'],\n",
    "            yerr=[coef_df['beta'] - coef_df['ci_low'],\n",
    "                  coef_df['ci_high'] - coef_df['beta']],\n",
    "            fmt='o', capsize=4, color='steelblue', markersize=8)\n",
    "\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax.axvline(x=-0.5, color='red', linestyle='--', linewidth=1.5, label='Treatment')\n",
    "ax.fill_betweenx(ax.get_ylim(), K_MIN - 0.5, -0.5, alpha=0.1, color='gray', label='Pre-treatment')\n",
    "\n",
    "ax.set_xlabel('Years Relative to Anchor Cutoff (k)', fontsize=12)\n",
    "ax.set_ylabel('Drift from Historical Baseline (βₖ)', fontsize=12)\n",
    "ax.set_title('Event Study: Structural Drift from Pre-Treatment Identity', fontsize=14)\n",
    "ax.set_xticks(range(K_MIN, K_MAX + 1))\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/structural_drift_event_study.png', dpi=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
